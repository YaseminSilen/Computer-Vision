{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 设置全局参数\n",
    "modellr = 2e-4\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 8\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # 注意这里只有一个值\n",
    "])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # 将图像转换为三通道\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # 对每个通道进行归一化\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "dataset_train = datasets.ImageFolder('Data/train', transform_train)\n",
    "dataset_validate = datasets.ImageFolder('Data/validate', transform_train)\n",
    "\n",
    "# 类别名称列表\n",
    "classes = ('0.0', '0.33', '0.67', '1.0')\n",
    "\n",
    "# 导入数据\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_validate, batch_size=BATCH_SIZE, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "# 应用 Kaiming He 初始化到最后一层\n",
    "nn.init.kaiming_normal_(model.fc.weight, mode='fan_out', nonlinearity='relu')\n",
    "model.fc.bias.data.fill_(0)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# 设置损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=modellr)\n",
    "\n",
    "# 设置学习率调度器\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 5.417996691620869\n",
      "\n",
      "Val set: Average loss: 2.9796, Accuracy: 269/601 (45%)\n",
      "\n",
      "Epoch: 2, Training Loss: 1.1970896688492403\n",
      "\n",
      "Val set: Average loss: 1.1111, Accuracy: 435/601 (72%)\n",
      "\n",
      "Epoch: 3, Training Loss: 0.8104978547148083\n",
      "\n",
      "Val set: Average loss: 0.8662, Accuracy: 428/601 (71%)\n",
      "\n",
      "Epoch: 4, Training Loss: 0.47706475967298384\n",
      "\n",
      "Val set: Average loss: 1.0915, Accuracy: 442/601 (74%)\n",
      "\n",
      "Epoch: 5, Training Loss: 0.40680004753496335\n",
      "\n",
      "Val set: Average loss: 1.1085, Accuracy: 439/601 (73%)\n",
      "\n",
      "Epoch: 6, Training Loss: 0.22060699258809505\n",
      "\n",
      "Val set: Average loss: 1.0922, Accuracy: 447/601 (74%)\n",
      "\n",
      "Epoch: 7, Training Loss: 0.10781360701050448\n",
      "\n",
      "Val set: Average loss: 1.1826, Accuracy: 447/601 (74%)\n",
      "\n",
      "Epoch: 8, Training Loss: 0.07966112940693679\n",
      "\n",
      "Val set: Average loss: 1.0723, Accuracy: 455/601 (76%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 定义训练过程\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += loss.item()\n",
    "        if (batch_idx + 1) % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                       100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
    "    ave_loss = sum_loss / len(train_loader)\n",
    "    print('Epoch: {}, Training Loss: {}'.format(epoch, ave_loss))\n",
    "\n",
    "# 定义验证过程\n",
    "def val(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "    print('\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100 * acc))\n",
    "    return test_loss\n",
    "\n",
    "# 训练和验证循环\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    val_loss = val(model, DEVICE, test_loader)\n",
    "    scheduler.step(val_loss)  # 更新学习率\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pth')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Task part:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7621 (503/660)\n",
      "Confusion Matrix:\n",
      " [[335  20   2  21]\n",
      " [ 40  27   1   7]\n",
      " [ 18   3   1   5]\n",
      " [ 33   6   1 140]]\n",
      "F1 Score (Micro): 0.7621\n",
      "F1 Score (Macro): 0.5253\n"
     ]
    }
   ],
   "source": [
    "# 加载模型状态字典\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "\n",
    "# 初始化计数器\n",
    "total_images = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "# 测试目录路径\n",
    "path = 'D:/9444f/Data/test'\n",
    "# 获取类别目录\n",
    "class_directories = os.listdir(path)\n",
    "\n",
    "# 初始化真实标签和预测结果列表\n",
    "all_targets = []\n",
    "all_preds = []\n",
    "\n",
    "# 遍历每个类别目录\n",
    "for class_index, class_dir in enumerate(class_directories):\n",
    "    class_dir_path = os.path.join(path, class_dir)\n",
    "    # 检查是否是一个目录\n",
    "    if os.path.isdir(class_dir_path):\n",
    "        # 列出目录中的文件\n",
    "        for file_name in os.listdir(class_dir_path):\n",
    "            file_path = os.path.join(class_dir_path, file_name)\n",
    "            # 检查是否是文件\n",
    "            if os.path.isfile(file_path):\n",
    "                total_images += 1\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        img = transform_test(img)\n",
    "                        img = img.unsqueeze(0)\n",
    "                        img = img.to(DEVICE)\n",
    "                        with torch.no_grad():\n",
    "                            out = model(img)\n",
    "                        _, pred = torch.max(out.data, 1)\n",
    "                        # 添加预测和真实标签到列表\n",
    "                        all_preds.append(pred.item())\n",
    "                        all_targets.append(class_index)\n",
    "                        # 更新正确预测计数器\n",
    "                        correct_predictions += (pred.item() == class_index)\n",
    "                except Exception as e:\n",
    "                    print(f'Error processing {file_name}: {e}')\n",
    "\n",
    "# 计算精度并打印\n",
    "accuracy = correct_predictions / total_images if total_images > 0 else 0\n",
    "print(f'Accuracy: {accuracy:.4f} ({correct_predictions}/{total_images})')\n",
    "\n",
    "# 计算并打印混淆矩阵\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# 计算并打印F1分数\n",
    "f1_micro = f1_score(all_targets, all_preds, average='micro')\n",
    "f1_macro = f1_score(all_targets, all_preds, average='macro')\n",
    "print(f'F1 Score (Micro): {f1_micro:.4f}')\n",
    "print(f'F1 Score (Macro): {f1_macro:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}